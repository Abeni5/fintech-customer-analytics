{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa1b6b6",
   "metadata": {},
   "source": [
    "# Task 1: Data Collection and Preprocessing\n",
    "This notebook contains the script to scrape and preprocess reviews from the Google Play Store for CBE, BOA, and Dashen Bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892e9325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 400 reviews for Commercial Bank of Ethiopia\n",
      "DataFrame for Commercial Bank of Ethiopia: (400, 6)\n",
      "Scraped 400 reviews for Bank of Abyssinia\n",
      "DataFrame for Bank of Abyssinia: (400, 6)\n",
      "Scraped 400 reviews for Dashen Bank\n",
      "DataFrame for Dashen Bank: (400, 6)\n",
      "Combined DataFrame shape: (1200, 6)\n",
      "Columns: ['review_id', 'review', 'rating', 'date', 'bank', 'source']\n",
      "Total reviews: 1200\n",
      "Missing data: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google_play_scraper import reviews, Sort\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import os  \n",
    "\n",
    "apps = {\n",
    "   'Commercial Bank of Ethiopia': 'com.combanketh.mobilebanking',\n",
    "    'Bank of Abyssinia': 'com.boa.boaMobileBanking',\n",
    "    'Dashen Bank': 'com.dashen.dashensuperapp'\n",
    "}\n",
    "\n",
    "def scrape_reviews(app_id, app_name, count=400):\n",
    "    try:\n",
    "        result, _ = reviews(app_id, lang='en', country='et', sort=Sort.NEWEST, count=count)\n",
    "        print(f\"Scraped {len(result)} reviews for {app_name}\")\n",
    "        reviews_list = []\n",
    "        for review in result:\n",
    "            reviews_list.append({\n",
    "                'review_id': review['reviewId'],\n",
    "                'review': review['content'],\n",
    "                'rating': review['score'],\n",
    "                'date': review['at'],\n",
    "                'bank': app_name,\n",
    "                'source': 'Google Play'\n",
    "            })\n",
    "        return pd.DataFrame(reviews_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {app_name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "all_reviews = []\n",
    "for app_name, app_id in apps.items():\n",
    "    df = scrape_reviews(app_id, app_name)\n",
    "    print(f\"DataFrame for {app_name}: {df.shape}\")\n",
    "    all_reviews.append(df)\n",
    "\n",
    "df_reviews = pd.concat(all_reviews, ignore_index=True)\n",
    "print(f\"Combined DataFrame shape: {df_reviews.shape}\")\n",
    "print(f\"Columns: {df_reviews.columns.tolist()}\")\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "if df_reviews.empty:\n",
    "    print(\"No reviews scraped. Consider using fallback dataset.\")\n",
    "else:\n",
    "    df_reviews = df_reviews.drop_duplicates(subset=['review_id'])\n",
    "    df_reviews['review'] = df_reviews['review'].fillna('')\n",
    "    df_reviews['rating'] = df_reviews['rating'].fillna(df_reviews['rating'].median())\n",
    "    df_reviews = df_reviews.dropna(subset=['date'])\n",
    "    df_reviews['date'] = pd.to_datetime(df_reviews['date']).dt.strftime('%Y-%m-%d')\n",
    "    df_reviews.to_csv('data/bank_reviews_cleaned.csv', index=False)\n",
    "    print(f\"Total reviews: {len(df_reviews)}\")\n",
    "    print(f\"Missing data: {df_reviews.isnull().mean().mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3223499",
   "metadata": {},
   "source": [
    "# Task 2: Sentiment and Thematic Analysis\n",
    "This section will include sentiment analysis using NLTK's VADER and thematic analysis of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fc2a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame shape: (1200, 6)\n",
      "Unique banks: ['Commercial Bank of Ethiopia' 'Bank of Abyssinia' 'Dashen Bank']\n",
      "Before save - Sample banks: ['Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia', 'Commercial Bank of Ethiopia']\n",
      "Saved to file, verifying...\n",
      "Verified DataFrame shape: (1200, 8)\n",
      "Verified Unique banks: ['Commercial Bank of Ethiopia' 'Bank of Abyssinia' 'Dashen Bank']\n",
      "Sentiment Analysis Results:\n",
      "sentiment_label\n",
      "Positive    750\n",
      "Neutral     312\n",
      "Negative    138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average Sentiment by Bank:\n",
      "bank\n",
      "Bank of Abyssinia              0.116311\n",
      "Commercial Bank of Ethiopia    0.318407\n",
      "Dashen Bank                    0.446234\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')  # Already downloaded, but ensure it runs\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df = pd.read_csv('C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Customer Experience Analytics for Fintech Apps\\\\fintech-customer-analytics\\\\notebook\\\\data\\\\bank_reviews_cleaned.csv')\n",
    "print(\"Loaded DataFrame shape:\", df.shape)\n",
    "print(\"Unique banks:\", df['bank'].unique())\n",
    "df['sentiment'] = df['review'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "df['sentiment_label'] = df['sentiment'].apply(lambda x: 'Positive' if x > 0.05 else 'Negative' if x < -0.05 else 'Neutral')\n",
    "print(\"Before save - Sample banks:\", df['bank'].head(10).tolist())\n",
    "df.to_csv('C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Customer Experience Analytics for Fintech Apps\\\\fintech-customer-analytics\\\\notebook\\\\data\\\\bank_reviews_with_sentiment.csv', index=False, mode='w')  # Explicit mode\n",
    "print(\"Saved to file, verifying...\")\n",
    "saved_df = pd.read_csv('C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Customer Experience Analytics for Fintech Apps\\\\fintech-customer-analytics\\\\notebook\\\\data\\\\bank_reviews_with_sentiment.csv')\n",
    "print(\"Verified DataFrame shape:\", saved_df.shape)\n",
    "print(\"Verified Unique banks:\", saved_df['bank'].unique())\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(\"\\nAverage Sentiment by Bank:\")\n",
    "print(df.groupby('bank')['sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14a7446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Themes (Common Words) Across All Banks: [('app', 506), ('good', 194), ('bank', 126), ('banking', 116), ('best', 109), ('dashen', 94), ('use', 85), ('one', 76), ('super', 73), ('mobile', 66)]\n",
      "\n",
      "Top 5 Themes for Commercial Bank of Ethiopia: [('app', 129), ('good', 88), ('best', 38), ('nice', 27), ('cbe', 25)]\n",
      "\n",
      "Top 5 Themes for Bank of Abyssinia: [('app', 167), ('good', 56), ('bank', 40), ('work', 33), ('boa', 30)]\n",
      "\n",
      "Top 5 Themes for Dashen Bank: [('app', 210), ('dashen', 91), ('banking', 72), ('super', 70), ('bank', 66)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Thematic Analysis\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\Customer Experience Analytics for Fintech Apps\\\\fintech-customer-analytics\\\\notebook\\\\data\\\\bank_reviews_with_sentiment.csv')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = ' '.join(df['review']).lower()\n",
    "words = re.findall(r'\\w+', words)\n",
    "words = [word for word in words if word not in stop_words]\n",
    "common_themes = Counter(words).most_common(10)\n",
    "print(\"Top 10 Themes (Common Words) Across All Banks:\", common_themes)\n",
    "\n",
    "for bank in df['bank'].unique():\n",
    "    bank_words = ' '.join(df[df['bank'] == bank]['review']).lower()\n",
    "    bank_words = re.findall(r'\\w+', bank_words)\n",
    "    bank_words = [word for word in bank_words if word not in stop_words]\n",
    "    bank_themes = Counter(bank_words).most_common(5)\n",
    "    print(f\"\\nTop 5 Themes for {bank}:\", bank_themes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
